## 1 消息丢失怎么办

### 1.1 RabbitMQ

![](..\cache\img\003.png)

![](..\cache\img\002.png)

- 生产者丢失数据

  ​	生产者在将数据发送到**mq**的过程中，可能因为网络原因请求超时而导致数据丢失。

  ​	此时可以选择使用`RabbitMQ`提供的事务功能，就是生产者在发送数据之前开启事务<code style='color:#c7254e'>channel.txSelect</code>，然后发送消息，如果消息没有成功被`RabbitMQ`接收到，那么生产者会受到异常报错，此时就可以回滚事务<code style='color:#c7254e'>channel.txRollback</code>，然后重试发送消息；如果收到了消息，那么可以提交事务<code style='color:#c7254e'>channel.txCommit</code>。

  ```java
  // 开启事务
  channel.txSelect
  try {
      // 这里发送消息
  } catch (Exception e) {
      channel.txRollback
  
      // 这里再次重发这条消息
  }
  
  // 提交事务
  channel.txCommit
  ```

  ​	问题是事务机制效率很低，开启事务之后吞吐量会很低，造成性能特别低。

  ​	一般情况下，我们可以开启<code style='color:#c7254e'>confirm</code>模式，在生产者那里设置开启<code style='color:#c7254e'>confirm</code>模式之后，之后每次发送的消息都会分配一个唯一的消息ID，如果写入了`RabbitMQ`之后，`RabbitMQ`会回传一个<code style='color:#c7254e'>ack</code>消息，告诉生产者这个消息已经入队了。如果`RabbitMQ`没能处理这个消息，那么会回调我们<code style='color:#c7254e'>nack</code>接口，告诉我们这个消息接受失败，此时可以使用重试策略。而且我们可以结合<code style='color:#c7254e'>confirm</code>模式再维护每个消息的ID状态，如果超过一定时间没有收到<code style='color:#c7254e'>ack</code>和<code style='color:#c7254e'>nack</code>回调，那么可以重试。

  ​	事务机制和<code style='color:#c7254e'>confirm</code>机制最大的不同在于，**事务机制是同步的**，在提交一个事务之后队列会阻塞在那里，但是<code style='color:#c7254e'>confirm</code>机制是异步的，在发送这个消息之后可以立即发送下一个消息，`RabbitMQ`在收到每个消息之后，都会异步回调我们的<code style='color:#c7254e'>ack</code>或者<code style='color:#c7254e'>nack</code>告知我们是否成功。

  ​	一般情况下，采用<code style='color:#c7254e'>confirm</code>机制即可。

- **mq**丢失数据

  ​	这种情况就是**消息队列**自己弄丢了数据，比如消息队列满了、服务器宕机了等等，这个时候必须开启`RabbitMQ`的持久化，将写入的消息写入到磁盘，服务器恢复正常状态之后、可以自动读取之前持久化过的数据。

  ​	设置持久化有两个步骤：

  - 创建<code style='color:#c7254e'>queue</code>的时候设置为持久化

    这样可以保证`RabbitMQ`持久化<code style='color:#c7254e'>queue</code>的元数据，但是不会持久化<code style='color:#c7254e'>queue</code>里的数据。

  - 发送消息的时候讲消息的<code style='color:#c7254e'>deliveryMode</code>设置为2

    将消息设置为持久化，此时<code style='color:#c7254e'>queue</code>里的数据也会持久化到磁盘中去。

  ​	必须同时设置这两个持久化才可以，哪怕`RabbitMQ`挂了，再次重启，也会从磁盘上重启回复<code style='color:#c7254e'>queue</code>，以及回复<code style='color:#c7254e'>queue</code>中的数据。

  ​	哪怕我们开启了持久化机制，也存在一种可能，就是这个消息写入到了`RabbitMQ`中，但是还没来得及持久化到磁盘上，此时`RabbitMQ`挂了，会导致此时内存中的极少数的数据丢失。这时候我们可以结合持久化和<code style='color:#c7254e'>confirm</code>机制，只有消息被持久化到磁盘之后，才会通知生产者<code style='color:#c7254e'>ack</code>了，所以哪怕实在持久化到磁盘之前，`RabbitMQ`挂了，数据丢了，生产者收不到<code style='color:#c7254e'>ack</code>，也是可以执行重新发送策略的。

- 消费者丢失数据

  ​	如果消息者收到了消息，还没来得及处理，结果进程挂了，比如消费者服务器重启了，那么久尴尬了，`RabbitMQ`会认为消息已经消费，这是数据就会丢失。

  ​	这时候需要借助`RabbitMQ`提供的<code style='color:#c7254e'>ack</code>机制，我们需要在消费者中关闭`RabbitMQ`的自动<code style='color:#c7254e'>ack</code>，这个通过一行<code style='color:#c7254e'>API</code>声明下就可以，然后每次自己代码里确保处理完的时候，再次在进程里手动<code style='color:#c7254e'>ack</code>一次。这样如果没有处理完，就不会有<code style='color:#c7254e'>ack</code>，那么`RabbitMQ`就会认为这个消息没有处理完，这时候`RabbitMQ`会把这个消息重新分配给别的`consumer`去处理，消息不会丢失。

### 1.2 Kafka

- 消费者丢失数据

  ​	`kafka`消费者收到消息之后会自动确认<code style='color:#c7254e'>offset</code>，此时`kafka`会认为已经消费了消息，如果此时消息还未处理服务器就宕机了，那么会导致消息丢失。

  ​	他的处理思路和`RabbitMQ`类似，关闭自动确认，启动手动提交<code style='color:#c7254e'>offset</code>，就可以保证数据不会丢失。但是此时存在着重复消费的可能性，比如消费者已经处理完数据，但是还没来得及<code style='color:#c7254e'>offset</code>，此时服务器宕机了，那么该消息会被另一个消费者消费，这时候我们自己从业务上保证消息的幂等性即可。

- **kafka**丢失数据

  ​	如果`kafka`的某个`broker`宕机，然后重新选举`partition`为`leader`。如果此时其他的follower刚好有些数据还没有同步，此时`leader`挂了，然后选举某个`follower`成`leader`之后，就会丢失一部分数据。

  ​	此时一般眼设置至少四个参数：

  - 给`topic`设置<code style='color:#c7254e'>replication.factor</code>参数：这个值必须大于1，这个是要求一个`leader`至少感知到有一个`follower`还跟自己保持联系，没掉队，这样才能保证leader挂了之后还有一个`follower`。
  - 在`kafka`服务端设置<code style='color:#c7254e'>min.insync.replicas</code>参数：这个值必须大于1，这个是要求一个 `leader` 至少感知到有至少一个` follower` 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 `follower`。
  - 在`producer`设置<code style='color:#c7254e'>acks=all</code>：这个是要求每条数据，必须是写入所有的`replicas`之后，才能认为是写入成功。
  - 在`producer`端设置<code style='color:#c7254e'>retries=MAX</code>：这个值可以尽可能的大一点，这个是要求一旦写入失败，那么会重试`MAX`次。

- 生产者会不会丢失数据

  ​	生产者如果设置了<code style='color:#c7254e'>acks=all</code>，理论上消息一定不会丢失。此时只有`leader`收到消息、并且所有的`follwer`都同步到了消息之后，才认为本次写入成功了，如果没满足这个条件，那么生产者会自动的重试`retries`次，直到成功。