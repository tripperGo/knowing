## 1 Kubernetes的基本概念

​	Kubernetes是一个高度自动化的资源控制系统，包含Node、pod、Replication Controller、Service等各种资源对象，几乎所有的资源对象都可以通过Kubernetes提供的kubectl工具（或者API server）执行增删改查操作，并将其保存在etcd中持久化存储。

### 1.1 Master

​	Kubernetes里的Master节点指的是集群控制节点，在每个Kubernetes集群里都需要有一个Master来负责整个集群的管理和控制，基本上Kubernetes的所有控制命令都会发给Master节点，他负责具体的执行过程。在Master节点上部署有如下进程：

- Kubernetes API Server

  ​	Kubernetes API Server是通过一个名为Kube-apiserver的进程提供服务。

  ​	提供K8s集群内所有资源对象（比如pod、RC、service）的增、删、改、查以及watch等Http rest接口，成为集群内各个功能模块之间交互和通信的中心枢纽，是整个系统的数据总线和数据中心。除此之外，他还有以下一些功能特性：

  - 是集群管理的API入口
  - 是资源配额控制的入口
  - 提供了完备的集群安全机制

- Controller Manager

  ​	Controller Manager通过名为Kube-controller-manager的进程提供服务。

  ​	K8s中所有资源对象的自动化控制中心。在K8S集群中，Controller Manager内部包含了Replication Controller、Node Controller、ResourceQuota Controller、Namespace Controller、ServiceAccount Controller、Token Controller、Service Controller以及Endpoint Controller这8中controller，每种controller都负责一种特定的资源的控制流程，而controller Manager是这些controller的核心管理者。

  ​	每一个controller都通过API Server提供的List-watch接口实时监控集群中特定资源的状态变化，当发生各种故障导致某资源对象的状态发生变化时，controller会尝试将其状态调整为期望的状态。比如当某个Node意外宕机时，Node Controller会及时发现此故障并执行自动化修复流程，确保集群始终处于预期的工作状态。Controller Manager是K8S中各种资源对象的管理者，是集群内部的管理控制中心，也是K8S自动化功能的核心。

- Scheduler

  ​	Scheduler是通过一个名为Kube-scheduler的进程提供服务的。kube-scheduler的作用是将待调度的pod（API新创建的POD、Controller Manager为补足副本而创建的POD等）按照特定的调度算法和调度策略绑定到某个合适的Node上，并将绑定信息写入进etcd中。简单来说，就是通过调度算法调度为待调度POD列表中的每个POD从Node列表中选择一个合适的Node。

  ​	随后，目标Node节点上的kubelet进程通过API Server监听到Kubernetes Scheduler产生的POD绑定事件，然后获取对应的POD清单，下载Image镜像并启动容器。

   - 预选策略

      - NoDishConflict

      - PodFitsResources

        计算备选pod和节点中已存在的POD的所有容器的需求资源总和，如果总和超过了备选Node所拥有的资源，则返回false，表明该Node不适合备选POD；否则返回true，表明该节点适合作为备选POD。

      - PodSelectorMatches

        判断备选节点是否包含备选POD的标签选择器指定的标签。如果Pod没有指定标签选择器，则直接返回true；否则、获取备选节点的标签信息，如果该节点包含Pod的标签选择器、则返回true，否则返回false。

   - 优选策略

      - LeastRequestedPriority

        该优选策略用于从备选节点上选出资源消耗最小的节点。计算在所有备选Node上运行的Pod和备选Pod的CPU占用量和内存占用量，取最低的。

      - CalculateNodeLabelPriority

        标签选择的方法，如果用户在配置文件中选择了该策略，在优先选择备选Node上存在该标签列表的Node。

      - BalancedResourceAllocation

        该优选策略用于从备选节点上选出资源消耗均衡的节点。计算在所有备选Node上运行的Pod和备选Pod的CPU占用量和内存占用量，取最均衡的。

### 1.2 Node

​	Node是K8S集群中的工作负载节点，每个Node都会被Master分配一些工作负载，当某个Node宕机的时候，该节点上的工作负责（Pod、容器）会被Master自动的转移到其他的Node上。每一个Node节点上运行着如下关键进程：

- kubelet

  负责Pod对应的容器的创建、启停等任务，同时于Master密切协作，实现集群管理的基本功能。

- Kube-proxy

  实现kubernetes service的通信与负载均衡。

- Docker engine

  docker引擎，负责本节点的容器的创建和管理工作。

​	Node可以在运行期间动态的增加到K8S集群中，前提是这个节点已经正确的安装、配置并启动了如上三个关键进程，在默认情况下kubelet会向master注册自己，一旦Node被纳入集群管理范围，kubelet进程就会定时向Master回报自身的信息，比如机器的CPU和内存占用，当前哪些Pod正在运行等信息，这样Master节点就可以知道每个Node的资源使用情况，并实现高效均衡的资源调度策略。儿某个Node在超时不上报信息时，会被Maser判定为“失联”，Node的状态被标记为不可用状态（Not Ready），随后Master会触发“工作负载大转移”的自动化流程。

### 1.3 Pod

​	Pod内部包含了一组docker容器，分为两类，一是pause容器（根容器），另一类是一个或多个紧密相关的用户业务容器。

​	Pod中的多个业务容器共享Pause容器的IP，volume，这样的设计既简化了密切相关的业务容器之间的通信问题，也很好的解决了他们之间的文件共享问题。K8S以业务不相关的Pause容器作为根容器，以Pause容器的生存或死亡状态代表该Pod的状态。K8S为每个Pod分配了为一个IP地址，Pod IP，一个Pod中所有容器共享此PodIP，在K8S集群中一个Pod里的容器和其他Node上的Pod容器能够直接通信。

​	Pod分为普通Pod和静态Pod，静态Pod没有存放在etcd中，而是被存放在某个具体的Node上的一个具体文件中，并且只会在本Node节点上启动、运行。普通Pod一旦被创建，就会被放入etcd中存储，随后会被master调度到某个Node上进行绑定，随后该Pod被对应的Node上的ku belet进程实例成一组相关的Docker容器并启动。

​	在Pod的定义文件中，我们可以对计算资源进行配额限定，设置requests（该资源的最小申请量，300m内存或者300mCPU），limits（该资源的最大申请量）。

### 1.4 Label

​	Label通常在资源对象定义时声明，也可以在对象创建后动态添加或者删除。Label就是标签，我们可以给每一个资源对象打上一个或者多个标签，随后通过Label Selector（标签选择器）查询和筛选拥有某些Label的资源对象。K8S使用标签选择器的方式实现了类似SQL的简单又通用的查询机制。

### 1.5 Replication Controller

​	一种资源对象，简称RC。它定义了一个期望的场景，声明某种Pod的副本数量，K8S集群会保持副本数量始终保持该数量。在RC中一定要定义这几个条件：

- Pod期待的副本数量
- 用于筛选目标Pod的Label Selector
- 当Pod副本数量小于期望值时，用于创建新Pod的Pod模板。

​	当我们定义了一个RC并执行创建命令之后，Master接待你上的Controller Manager组建就会得到通知，定期巡检系统当中存活的目标Pod，并确保目标Pod实例的数量刚好等于期望值，如果系统有过多的Pod副本在运行，那么就会停掉一些Pod，否则会再创建几个新的Pod。

​	删除RC并不会影响通过RC已经创建好了的Pod，为了删除所有Pod，可以设置replicas=0，然后更新RC。另外还可以通过kubectl的stop和delete命令来一次性的删除RC和RC控制的全部Pod

​	**滚动升级**：启动一个新版本的Pod，关闭一个旧版本的Pod，平滑的滚动升级。

​	k8s1.2版本以后，逐渐使用Replica Set和DeployMent来替代RC。不过我们很少直接操作RS，RS主要是被Deploy这个资源对象所使用，从而形成一套Pod的创建、删除、更新的编排机制。RS支持基于集合的标签选择器，RC只能使用等式的标签选择器。

​	RC和RS的一些特性与作用：

- 在大多数情况下，我们通过定义一个RC/RS实现Pod的创建及副本数量的自动控制。
- 在RC/RS里包含完整的Pod定义模板
- RC/RS通过标签选择器实现对Pod副本的自动控制
- 通过改变RC/RS里的Pod副本数量，可以实现Pod的自动扩缩容
- 通过改变RC/RS里的Pod模板中的镜像版本，可以实现Pod的滚动升级

### 1.6 Deployment

​	DeployMent内部使用Replica Set来实现编排。

​	在DeployMent中我们可以知道当前Pod部署的进度，能够查看已就绪的Pod和未完成的Pod。

### 1.7 Horizontal Pod Autoscaler

​	我们可以通过手工执行kubectl scale命令来实现Pod的扩容和缩容操作，这体现不出K8s的自动化和智能化的特性。HPA也是一种资源对象，通过追踪分析指定RC控制的所有目标Pod的负载变化情况，来确定是否需要有针对性地调整目标Pod的副本数量。当前HPA有两种方式作为Pod负载的度量指标：

- CPUUtilzationPercentage

  一个算数平均值，也就是目标Pod所有副本的CPU使用率的一个平均值。比如当算数平均值大于80%，我们就触发自动扩容操作，当小于80%时，就触发自动缩容操作。

- 应用程序自定义的度量指标，比如服务每秒的请求数

### 1.8 StatefulSet

​	有状态服务，比如Mysql服务等。StatefulSet要求每个节点都有固定的IP；集群的规模不能随意变化；每个节点都是有状态的，通常会持久化到永久存储中；如果磁盘损坏、则集群中的某个节点无法正常运行，集群功能受损。

- StatefulSet里的每个Pod都有稳定、唯一的网络标示，可以用来发现集群内的其他成员。例如StatefulSet的名称为mysql，那么第一个Pod就自动初始化名称为mysql-0，第二个叫mysql-2。
- StatefulSet控制的Pod副本的启停顺序是受控制的，操作第n个Pod时，前n-1个Pod必须已经是运行的状态
- StatefulSet里的Pod采用稳定的持久化存储卷，删除Pod时不会删除与StatefulSet相关的存储卷。

### 1.9 Service

​	k8s集群中的每一个Service其实就是我们微服务中的某一个服务。k8s的Service定义了一个服务的访问入口地址，前端的应用Pod通过这个入口ClusterIP+targetport访问其背后的一组由Pod副本组成的集群实例，Service与其后端的Pod副本之间是通过Label Selector来实现无缝对接的。RC/RS的作用其实就是保证Service的服务能力和服务质量始终符合预期标准。

​	运行在Node上的kube-proxy进程具有软负载的功能，负责把对Service的请求转发到后端的某一个Pod实例上，并在内部实现服务的负载均衡与会话保持机制。K8S为每一个Service都分配了一个全局唯一的虚拟的 Cluster IP，每个服务都具备一个唯一IP地址，服务间的调用就变成了最基础的TCP网络通信问题。Service一旦创建，k8s就会自动为他分配一个可用的cluster ip，并且在Service的整个生命周期都不会发生变化，因此服务发现这个问题在k8s中能够轻松解决，只需要使用service的name与service的cluster IP 地址做一个DNS域名映射即可解决。

- 服务发现

  使用service的name与service的cluster IP 地址做一个DNS域名映射。

- 外部系统访问service

  - Node IP：Node节点的物理IP地址

  - Pod IP

    Pod IP是每个Pod的IP地址，他是Docker根据docker0网桥的IP地址段进行分配的，通常是一个虚拟的二层网络。真实的访问是走的Node IP所在的物理网卡。

  - Cluster IP：Service的虚拟IP

    - Cluster IP仅存在于Service这个对象
    - Cluster IP不能被ping，因为它是虚拟的，没有一个实体网络对象来响应
    - Cluster IP只能结合service port来组成一个具体的通信端口，单独的Cluster IP不具备通信基础。