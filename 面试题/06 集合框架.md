## 1 HashMap

### 1.1 初始大小

​	HashMap默认的初始大小为16，可以根据业务需求赋值一个初始值，尽量避免扩容操作；

### 1.2 装载因子和动态扩容

​	装载因子默认是0.75，当HashMap中元素个数超过散列表容量*0.75之后，就会启动扩容操作，每次都会扩展为原来的2倍大小。

### 1.3 散列冲突解决方法

​	HashMap采用链表法解决Hash冲突。在JDK1.8版本中，引入红黑树，当链表长度大于8时，链表转换为红黑树。这时候利用红黑树快速增删改擦汗的特性、提高HashMap的性能。当红黑树节点个数少于8时，又会将红黑树转换为链表。因为在数据量较小的情况下，红黑树需要维护平衡，比起链表来性能并没有明显的优势。

**其他算法**

- 开放寻址法

  当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。

  在散列表中查找数据的过程和插入操作有点类似，我们通过散列函数计算出要查找的元素的键值对应的散列值，然后比较散列表中下标为散列值的元素和要查找的元素是否相同，如果相同该元素就是我们要查找的元素，否则就顺序往后查找。如果遍历完数组、没有找到相同的值，则说明该值不在散列表中。

  这种算法就是线性探测法，他有很大的弊端，当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。极端情况下，我们可能需要探测整个散列表，所以最坏情况下的时间复杂度为 O(n)。同理，在删除和查找时，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据。

  - 二次探测

    线性探测法每次探测的步长为1，比如hash(key)+1、hash(key)+2。而二次探测法每次步长为线性探测的二次方，比如hash(key)+1、hash(key)+4...

  - 双重探测

    双重探测就是我们先用第一个散列函数进行探测，如果还没找到空闲位置，那么就换第二种探测算法。

  - **LinkedHashMap**

    **LinkedHashMap**采用开放寻址法来解决hash冲突。开放寻址法不像链表法，需要拉很多链表。散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存加快查询速度。而且，这种方法实现的散列表，序列化起来比较简单。

    用开放寻址法解决冲突的散列表，删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据。而且，在开放寻址法中，所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。所以，使用开放寻址法解决冲突的散列表，装载因子的上限不能太大。这也导致这种方法比链表法更浪费内存空间。

## 2 LinkedHashMap

`LinkedHashMap`是`HashMap`的子类，但内部还有一个双向链表维护键值对的顺序，每个键值对既位于哈希表中，也位于这个双向链表中。`LinkedHashMap`支持两种顺序，一种是插入顺序，另外一种是访问顺序。

`LinkedHashMap`在添加和获取元素的时候，通过`addBefore`方法保证元素插入到链表结尾。

## 3 线程安全集合

### 3.1 CopyOnWriteArrayList 

​	`ArrayList` 并不是线程安全的，在读线程在读取 `ArrayList` 的时候如果有写线程在写数据的时候，基于` fast-fail `机制，会抛出**ConcurrentModificationException**异常。 `CopyOnWriteArrayList` 容器可以保证线程安全，保证读读之间在任何时候都不会被阻塞。

​	如果只使用读写锁的话，在写锁被获取之后，读写线程被阻塞，只有当写锁被释放后读线程才有机会获取到锁从而读到最新的数据，站在**读线程的角度来看，即读线程任何时候都是获取到最新的数据，满足数据实时性**。` CopyOnWriteArrayList` 就是通过 写时复制的思想来通过延时更新的策略来实现数据的最终一致性，并且能够保证读线程间不阻塞。

​	COW 通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行 Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。对 CopyOnWrite 容器进行并发的读的时候，不需要加锁，因为当前容器不会添加任何元素。所以 CopyOnWrite 容器也是一种读写分离的思想，延时更新的策略是通过在写的时候针对的是不同的数据容器来实现的，放弃数据实时性达到数据的最终一致性。

- 实现原理

  - get方法

    get方法和ArrayList没有区别，因为读操作不存在任何线程安全问题。

  - add方法

    - add方法采用`ReentrantLock`，保证同一时刻只有一个写线程正在进行数组的复制，否则的话内存中会有多份被复制的数据；

    - 数组引用是 volatile 修饰的，因此将旧的数组引用指向新的数组，根据 volatile 的 happens-before 规则，写线程对数组引用的修改对读线程是可见的。
    - 由于在写数据的时候，是在新的数组中插入数据的，从而保证读写实在两个不同的数据容器中进行操作。

    ```java
    public boolean add(E e) {
        final ReentrantLock lock = this.lock;
    	//1. 使用Lock,保证写线程在同一时刻只有一个
        lock.lock();
        try {
    		//2. 获取旧数组引用
            Object[] elements = getArray();
            int len = elements.length;
    		//3. 创建新的数组，并将旧数组的数据复制到新数组中
            Object[] newElements = Arrays.copyOf(elements, len + 1);
    		//4. 往新数组中添加新的数据
    		newElements[len] = e;
    		//5. 将旧数组引用指向新的数组
            setArray(newElements);
            return true;
        } finally {
            lock.unlock();
        }
    }
    
    ```

- 缺点

  - 内存占用多
  - `CopyOnWrite `容器只能保证数据的最终一致性，不能保证数据的实时一致性。

### 3.2 ConcurrentHashMap

ConcurrentHashMap采用分段锁的方式，只锁hash表的一部分。

- ConcurrentHashMap中维护着一个Segment数组，每个Segment可以看做是一个HashMap。

- 而Segment本身继承了ReentrantLock，它本身就是一个锁。

- 在Segment中通过HashEntry数组来维护其内部的hash表。

只要我们的hash值足够分散，那么每次put的时候就会put到不同的segment中去。 而segment自己本身就是一个锁，put的时候，当前segment会将自己锁住，此时其他线程无法操作这个segment， 但不会影响到其他segment的操作。这个就是锁分段带来的好处。

**线程安全的put**

```java
public V put(K key, V value) {
    Segment<K,V> s;
    if (value == null)
        throw new NullPointerException();
    int hash = hash(key);
    int j = (hash >>> segmentShift) & segmentMask;

    // 根据key的hash定位出一个segment，如果指定index的segment还没初始化，则调用ensureSegment方法初始化
    if ((s = (Segment<K,V>)UNSAFE.getObject          // nonvolatile; recheck
         (segments, (j << SSHIFT) + SBASE)) == null) //  in ensureSegment
        s = ensureSegment(j);
    // 调用segment的put方法
    return s.put(key, hash, value, false);
}
```

最终会调用segment的put方法，将元素put到HashEntry数组中。

```java
final V put(K key, int hash, V value, boolean onlyIfAbsent) {
    // 因为segment本身就是一个锁
    // 这里调用tryLock尝试获取锁
    // 如果获取成功，那么其他线程都无法再修改这个segment
    // 如果获取失败，会调用scanAndLockForPut方法根据key和hash尝试找到这个node，如果不存在，则创建一个node并返回，如果存在则返回null
    // 查看scanAndLockForPut源码会发现他在查找的过程中会尝试获取锁，在多核CPU环境下，会尝试64次tryLock()，如果64次还没获取到，会直接调用lock()
    // 也就是说这一步一定会获取到锁
    HashEntry<K,V> node = tryLock() ? null :
        scanAndLockForPut(key, hash, value);
    V oldValue;
    try {
        HashEntry<K,V>[] tab = table;
        int index = (tab.length - 1) & hash;
        HashEntry<K,V> first = entryAt(tab, index);
        for (HashEntry<K,V> e = first;;) {
            if (e != null) {
                K k;
                if ((k = e.key) == key ||
                    (e.hash == hash && key.equals(k))) {
                    oldValue = e.value;
                    if (!onlyIfAbsent) {
                        e.value = value;
                        ++modCount;
                    }
                    break;
                }
                e = e.next;
            }
            else {
                if (node != null)
                    node.setNext(first);
                else
                    node = new HashEntry<K,V>(hash, key, value, first);
                int c = count + 1;
                if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                    // 扩容
                    rehash(node);
                else
                    setEntryAt(tab, index, node);
                ++modCount;
                count = c;
                oldValue = null;
                break;
            }
        }
    } finally {
        // 释放锁
        unlock();
    }
    return oldValue;
}
```

**线程安全的扩容**

ConcurrentHashMap的扩容只针对每个segment中的HashEntry数组进行扩容。ConcurrentHashMap在rehash的时候是有锁的，所以在rehash的过程中，其他线程无法对segment的hash表做操作，这就保证了线程安全。

### 3.3 CopyOnWriteArrayList 



## 4 Queue

### 4.1 阻塞队列

**BlockingQueue** 

当队列已满，往队列中添加元素的操作会被阻塞；

当队列为空，从队列中去除元素的操作会被阻塞。

![1589784121560](F:/workspace/refactor/knowing/cache/img/1589784121560.png)

 **四组操作**

|     操作     | 抛出异常 | 返回布尔值，不抛出异常 | 阻塞、等待 | 超时等待  |
| :----------: | :------: | :--------------------: | :--------: | :-------: |
|     入队     |   add    |         offer          |    put     | offer(,,) |
|     出队     |  remove  |          poll          |    take    | poll(,,)  |
| 查看队首元素 | element  |          peek          |     -      |     -     |

### 4.2 同步队列

> 没有容量，进去一个元素，必须等待消费完之后，才能往里面放入下一个元素

```java
public static void main(String[] args) {
    BlockingQueue<Integer> queue = new SynchronousQueue<>();

    new Thread("生产队列") {
        @Override
        public void run() {

            try {
                for (int i = 0; i < 10; i++) {
                    System.out.println(Thread.currentThread().getName() + " ==> 生产消息：" + i);
                    queue.put(i);
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }.start();

    new Thread("消费队列") {
        @Override
        public void run() {
            for (int i = 0; i < 10; i++) {
                try {
                    TimeUnit.SECONDS.sleep(1);
                    System.out.println(Thread.currentThread().getName() + " ==> 消费消息：" + queue.take());
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }.start();
}
```

